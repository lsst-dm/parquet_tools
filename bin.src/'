#!/usr/bin/env python3
#
# This file is part of parquet_tools.
#
# Developed for the LSST Data Management System.
# This product includes software developed by the LSST Project
# (http://www.lsst.org).
# See the COPYRIGHT file at the top-level directory of this distribution
# for details of code ownership.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
'''
Usage: csv2pq [options] [infile [outfile]]

options:
--auto         ignore type in schema file, use auto conversion.
--cchar <c>    character designating a comment in infile.
--compress <t> specify the compression algorithm to use; where <t> is one of
               brotli, gzip, LZO, LZ4, snappy (default), ZSTD, or none which
               disables compression.
--debug        enables debug output.
--display      display schema conversions, infile and outfile are optional.
               If infile is present, it is checked for consistency with the
               schema. Specifying an outfile performs a conversion.
--flavor <f>   output flavor. For spark compatibility specify "spark".
--intnan <n>   the integer value to use for "null" (default is 0).
--mmap         use mmap() to read the input file, if possible.
--nodict       do not use dictionary encoding for the output file,
--null <seq>   the csv sequence designating a null value (default \\N).
--replace      if the output file exists, it is removed.
--rgsize <n>   the number of rows per row group (default all rows).
--schema <fn>  the file that describes the schema. The format is:
               <colname> <coltype> [NOT NULL][,]
--skip         skip conversion if the output file already exists.
--sep <c>      the csv field character separator (default comma).
--verbose      produce additional explanatory output.
--verify       checks for infile and outfile consistency. This check requires
               reading back outfile after it is created.

infile         the file name to be converted. Specifying a single dash reads
               stdin for a newline separated list of files to be converted.
outfile        the output file name unless infile is a dash. Then it must be
               a "[=dir/][-sfx]+sfx" template. For each infile its directory
               path is replaced by "dir/", if specified; "-sfx" removes the
               specified suffix and "+sfx" adds the specified suffix to
               produce the outfile name.

Notes: 1) Specifying --skip plus --replace skips all but the last existing
          file after which --replace goes into effect.
'''

# *****************************************************************************
# *                                c s v 2 p q                                *
# *****************************************************************************

from __future__ import print_function

import fileinput
import os
import sys
import textwrap

import pandas as pd
import pyarrow as pa

import pyarrow.parquet as pq

from csv2pq_cmdinfo import CmdInfo

from csv2pq_handler import getHandler

from csv2pq_schema import chkSchema, getSchema, TypeInfo

from csv2pq_utils import ePrint, Fatal, getVal


# *****************************************************************************
# *                         A p p l y T e m p l a t e                         *
# *****************************************************************************

def ApplyTemplate(tmplt):
    "Generate output file names from a template."

    # Get optional directory
    #
    sTmp = tmplt
    xDir = ''
    if tmplt[0:1] == '=':
        n = tmplt.rfind('/')
        if n < 0: Fatal(3, 'directory specification in template', sTmp)
        xDir = tmplt[1:n+1]
        if n < len(tmplt)-1: tmplt = tmplt[n+1:]
        else: tmplt = ''

    # Get suffixes
    #
    dSfx = ''
    aSfx = ''
    if tmplt:
        if tmplt[0:1] == '-' and len(tmplt) > 1:
            n = tmplt.find('+')
            if n < 0:
                dSfx = tmplt[1:]
                tmplt = ''
            else:
                dSfx = tmplt[1:n]
                tmplt = tmplt[n:]
        if tmplt[0:1] == '+' and len(tmplt) > 1:
            aSfx = tmplt[1:]
        else:
            if tmplt: Fatal(3, 'suffix specification in template', sTmp)

    # Apply template to generate output file names
    #
    for inFile in CmdInfo.fIN:
        if xDir:
            n = inFile.rfind('/')
            if n >= 0:
                inFile = xDir+inFile[n+1:]
            else:
                inFile = xDir+inFile

        if dSfx and inFile.endswith(dSfx):
            inFile = inFile[0:len(inFile)-len(dSfx)]

        if aSfx: inFile += aSfx

        CmdInfo.fOUT.append(inFile)


# *****************************************************************************
# *                                 U s a g e                                 *
# *****************************************************************************

def Usage():
    "Display how to use this command."

    print(__doc__)

    dlist = list(TypeInfo.table.keys())
    dlist.sort()
    dtypes = ', '.join(dlist)
    note = '2) The following schema coltypes are support: ' + dtypes
    indini = '       '
    indent = indini
    for line in textwrap.wrap(note):
        print(indent + line)
        indent = indini + '   '
    exit(0)


# *****************************************************************************
# *                                C o n f i g                                *
# *****************************************************************************

def Config(argv):
    "Parse command line options and very correctness."
    global FIN, FOUT, OPT, BLAB, DBG
    doDisplay = False
    doCheck = True
    schFile = ''
    inFile = ''
    compTypes = ['NONE', 'NAPPY', 'GZIP', 'LZO', 'BROTLI', 'LZ4', 'ZST']

    # Parse all options, they must appear first.
    #
    while argv and argv[0][0] == '-':
        opname = argv.pop(0)
        if opname == '--auto': CmdInfo.OPT['ato'] = True

        elif opname == '--cchar':
            CmdInfo.OPT['cmt'] = getVal('cchar', argv)
            if len(CmdInfo.OPT['cmt']) != 1:
                Fatal(3, 'cchar value', CmdInfo.OPT['sep'])

        elif opname == '--compress':
            compval = getVal('compression type', argv)
            CmdInfo.OPT['cmp'] = compval.upper()
            if CmdInfo.OPT['cmp'] not in compTypes:
                Fatal(3, 'compression type', compval)

        elif opname == '--debug' or opname == '-d': CmdInfo.dbg = True

        elif opname == '--display': doDisplay = True

        elif opname == '--hdr': CmdInfo.OPT['hdr'] = 0

        elif opname == '--help': Usage()

        elif opname == '--flavor':
            CmdInfo.OPT['flv'] = getVal('flavor', argv)
            if CmdInfo.OPT['flv'] != 'spark': Fatal(3, 'flavor', compval)

        elif opname == '--intnan':
            intnan = getVal('intnan', argv)
            try:
                iNum = int(intnan)
                CmdInfo.OPT['nan'] = str(iNum)
            except Exception:  # We don't care what kind it is
                Fatal(3, 'intnan', intnan)

        elif opname == '--mmap': CmdInfo.OPT['map'] = True

        elif opname == '--nochk': doCheck = False

        elif opname == '--nodict': CmdInfo.OPT['dct'] = False

        elif opname == '--null':
            CmdInfo.OPT['nil'] = getVal('null', argv)
            CmdInfo.OPT['dna'] = False

        elif opname == '--replace': CmdInfo.OPT['rep'] = True

        elif opname == '--rgsize':
            rgsz = getVal('rgsize', argv)
            try:
                iNum = int(rgsz)
                CmdInfo.OPT['rgs'] = str(iNum)
            except Exception:  # We don't care what kind it is
                Fatal(3, 'rgsize', rgsz)

        elif opname == '--schema':
            schFile = getVal('schema file', argv)

        elif opname == '--sep':
            CmdInfo.OPT['sep'] = getVal('sep', argv)
            if len(CmdInfo.OPT['sep']) != 1:
                Fatal(3, 'sep value', CmdInfo.OPT['sep'])

        elif opname == '--skip': CmdInfo.OPT['skp'] = True

        elif opname == '--verbose': CmdInfo.blab = True

        elif opname == '--verify': CmdInfo.OPT['ver'] = True

        elif opname == '-':
            inFile = opname
            break

        else: Fatal(3, 'option', opname)

    # Check for skip/replace action
    #
    if CmdInfo.OPT['rep'] and CmdInfo.OPT['skp']:
        CmdInfo.OPT['skr'] = True
        CmdInfo.OPT['rep'] = False

    # Adjust the header option based on the presence of schema
    #
    if CmdInfo.OPT['hdr'] is not None and schFile:
        CmdInfo.OPT['hdr'] = None
        CmdInfo.OPT['ign'] = 1

    # Resolve he input file
    #
    if not inFile:
        if not argv or not len(argv):
            if not doDisplay: Fatal(2, 'input file')
            else:
                inFile = ''
        else:
            inFile = argv.pop(0)
            CmdInfo.fIN.append(inFile)
    else:
        try:
            for line in fileinput.input():
                inFile = line.rstrip('\n')
                if not os.path.exists(inFile):
                    Fatal(1, 'Input file "' + inFile + '" not found')
                if not os.path.isfile(inFile):
                    Fatal(1, 'Input file "' + inFile + '" is not a file')
                CmdInfo.fIN.append(inFile)
        except Exception:  # We don't care what kind it is
            e = sys.exc_info()[1]
            Fatal(0, 'Unable to get input files from stdin', e)

    # If an output file is specified, make sure it's contextually compatible
    #
    if not argv or not len(argv):
        outFile = ''
    else:
        outFile = argv.pop(0)
        if outFile[0:1] in '+-=':
            ApplyTemplate(outFile)
        elif len(CmdInfo.fIN) > 1:
            Fatal(1, "non templated output file is " +
                     "incompatible with multiple input files")
        else:
            CmdInfo.fOUT.append(outFile)

    # Process the schema file and set appropiate header option
    #
    if not schFile:
        if doDisplay:
            Fatal(2, 'Unable to do --display because schema')
    else:
        getSchema(schFile, doDisplay)
        if doCheck:
            for inFile in CmdInfo.fIN: chkSchema(inFile)

    # if we have no output file then we are done
    #
    if not outFile: exit(0)


# *****************************************************************************
# *                               C o n v e r t                               *
# *****************************************************************************

def Convert(inPut, outFile):
    "Convert a csv file to a parquet file. Input may be a path or IO object."
    global OPT, colNames, colTypes

    try:
        df = pd.read_csv(inPut, header=CmdInfo.OPT['hdr'],
                         names=CmdInfo.colNames,
                         sep=CmdInfo.OPT['sep'], na_values=CmdInfo.OPT['nil'],
                         keep_default_na=CmdInfo.OPT['dna'],
                         dtype=CmdInfo.colTypes, skiprows=CmdInfo.OPT['ign'])
    except Exception:  # We don't care what kind it is
        e = sys.exc_info()[1]
        Fatal(0, 'Unable to create pandas dataframe', e)

    # If we need to verify, get the column list for the data frame
    #
    if CmdInfo.OPT['ver']: cVec1Len = len(list(df))

    # Convert dataframe to a pyarrow table
    #
    try:
        table = pa.Table.from_pandas(df)
    except Exception:  # We don't care what kind it is
        e = sys.exc_info()[1]
        Fatal(0, 'Unable to create arrow table', e)

    # Now write out the dataframe as a parquet file (df.to_parquet missing)
    #
    try:
        pq.write_table(table, outFile,
                       compression=CmdInfo.OPT['cmp'],
                       flavor=CmdInfo.OPT['flv'],
                       row_group_size=CmdInfo.OPT['rgs'],
                       use_dictionary=CmdInfo.OPT['dct'])
    except Exception:  # We don't care what kind it is
        e = sys.exc_info()[1]
        Fatal(0, 'Unable to create parquet file', e)

    # If we are not verifying the write, then exit.
    #
    if not CmdInfo.OPT['ver']: return

    # Read back the table
    #
    try:
        table2 = pa.parquet.read_table(outFile)
    except Exception:  # We don't care what kind it is
        e = sys.exc_info()[1]
        Fatal(0, 'Unable to read parquet file', e)

    # Convert it to a pandas table
    #
    try:
        df2 = table2.to_pandas()
    except Exception:  # We don't care what kind it is
        e = sys.exc_info()[1]
        Fatal(0, 'Unable to convert parquet table to pandas', e)

    # Get the column in the read back table and make sure it's consistent
    #
    cVec2Len = len(list(df2))
    if cVec1Len == cVec2Len and cVec1Len == len(CmdInfo.colNames):
        if CmdInfo.blab:
            ePrint('Output file', outFile, 'verified with',
                   cVec1Len, 'columns.')
    else:
        ePrint('Output file', outFile, 'verification failed.')
        ePrint(len(CmdInfo.colNames), 'cvs cols ->', cVec1Len,
               'pandas cols ->', cVec2Len, 'parquet cols.')
        exit(77)


# *****************************************************************************
# *                          M a i n   P r o g r a m                          *
# *****************************************************************************

# Strip off the first argument (the program name) and parse the command line
#
sys.argv.pop(0)
Config(sys.argv)

# Do some debugging
#
if CmdInfo.dbg:
    ePrint('cols=', CmdInfo.colNames, 'type=', CmdInfo.colTypes,
           'opt=', CmdInfo.OPT)

# Process all input files
#
for inFile in CmdInfo.fIN:

    # Make sure output file does not exist unless --replace or --skip specified
    #
    outFile = CmdInfo.fOUT.pop(0)
    ofHere = os.path.exists(outFile)

    if os.path.exists(outFile):
        if CmdInfo.OPT['skr']:
            if not CmdInfo.fOUT or not os.path.exists(CmdInfo.fOUT[0]):
                CmdInfo.OPT['skr'] = False
                CmdInfo.OPT['rep'] = True

        if CmdInfo.OPT['rep']:
            try:
                os.remove(outFile)
            except Exception:  # We really don't care what kind it is
                e = sys.exc_info()[1]
                Fatal(0, 'Unable to replace file ' + outFile, e)
        elif CmdInfo.OPT['skp']:
            if (CmdInfo.blab):
                ePrint("Skipping file", inFile, "output file",
                       outFile, "exists.")
            continue

        else:
            Fatal(1, 'Output file "' + outFile + '" already exists')

    # Indicate what we are doing
    #
    if CmdInfo.blab: ePrint("Converting", inFile, "to", outFile, "...")

    # Check if we need to manually handle nulls for integer columns. In any
    # case simply convert the input be it a file of i/o object
    #
    if CmdInfo.colNVChk: inFile = getHandler(inFile)
    Convert(inFile, outFile)
